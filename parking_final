#include "StereoVision.h"


Mat StereoVision::undistortFrame(Mat& frame)
{

	Mat cameraMatrix = Mat::eye(3,3,CV_64FC1);
	Mat distCoeffs = Mat::zeros(1,5,CV_64FC1);
	Mat dst;
	cameraMatrix = (Mat1d(3,3) << 509.5140, 0, 321.9972, 0, 510.5093, 258.7457, 0., 0., 1. );
	distCoeffs = (Mat1d(1,5) << 0.0891, -0.1673, 0., 0., 0.);
	// newCameraMatrix = getOptimalNewCameraMatrix(cameraMatrix, distortionParameters, { frame.cols, frame.rows }, 1);
	
	undistort(frame, dst, cameraMatrix, distCoeffs);

	return dst;
}


/**
 * @brief HSV값으로 영상을 이진화하는 함수
 * 
 * @param frame 입력하고자 하는 화면
 * @param camera 카메라 번호 0 = 왼쪽, 1 = 오른쪽
 * @return Mat 
 */
Mat StereoVision::add_HSV_filter(Mat& frame, int camera) {

	// Blurring the frame to reduce noise
	// GaussianBlur(frame, frame, { 5,5 }, 0);

	// Convert to HSV
	cvtColor(frame, frame, COLOR_BGR2HLS);
	// cvtColor(frame, frame, COLOR_BGR2HSV);

	Mat mask;

	// logitech c930e
	// vector<int> lowerLimitRedRight = { 10, 160, 100 };     // Lower limit for yellow
	// vector<int> upperLimitRedRight = { 40, 255, 255 };	 // Upper limit for yellow
	// vector<int> lowerLimitRedLeft = { 10, 160, 100 };     // Lower limit for yellow
	// vector<int> upperLimitRedLeft = { 40, 255, 255 };	 // Upper limit for yellow


	vector<int> lowerLimitRedRight = { 0, 190, 0 };     // Lower limit for white 세번째꺼만 바꾸는거
	vector<int> upperLimitRedRight = { 255, 255, 255 };	 // Upper limit for white
	vector<int> lowerLimitRedLeft = { 0, 190, 0 };     // Lower limit for white
	vector<int> upperLimitRedLeft = { 255, 255, 255 };	 // Upper limit for white

	if (camera == 1) {
		inRange(frame, lowerLimitRedRight, upperLimitRedRight, mask);
	} else {
		inRange(frame, lowerLimitRedLeft, upperLimitRedLeft, mask);
	}

	// dilate(mask, mask, Mat(), Point(-1, -1), 3);
	// erode(mask, mask, Mat(), Point(-1, -1), 3);

	return mask;
}

Mat StereoVision::find_edge(Mat& frame, int camera) {

	int center_x = frame.cols /2 - 30;
	int center_y = frame.rows /4 + 10;

	// int center_x = frame.cols /2 - 150;
	// int center_y = frame.rows /4;

	Mat gray_image;
	cvtColor(frame, gray_image, CV_RGB2GRAY);

	GaussianBlur(gray_image,gray_image, Size(3,3),2);
	// imshow("gau", gray_image);

	if(camera != 0)
	{
		center_x = center_x - 20;
		center_y = center_y + 10;
	}

	Mat dst = Mat::zeros(frame.size(), CV_8UC1 );
	
	for (int r = 0; r < frame.rows; r++)
	{
        for (int c = center_x; c < frame.cols-2; c++)
		{
			if((gray_image.at<uchar>(r, c+1) + gray_image.at<uchar>(r, c+2) + gray_image.at<uchar>(r, c+3) + gray_image.at<uchar>(r, c+4) + gray_image.at<uchar>(r, c+5))-5*gray_image.at<uchar>(r, c) > 80) // 60
			{
				dst.at<uchar>(r, c-1) = 255;
				dst.at<uchar>(r, c) = 255;
				dst.at<uchar>(r, c+1) = 255;
			}
        }
    }

	for (int r = 0; r < frame.rows; r++)
	{
        for (int c = 0; c < center_x; c++)
		{
			if(5*gray_image.at<uchar>(r, c) - (gray_image.at<uchar>(r, c+1) + gray_image.at<uchar>(r, c+2) + gray_image.at<uchar>(r, c+3) + gray_image.at<uchar>(r, c+4) + gray_image.at<uchar>(r, c+5)) > 80) // 60
			{
				dst.at<uchar>(r, c-1) = 255;
				dst.at<uchar>(r, c) = 255;
				dst.at<uchar>(r, c+1) = 255;
			}
        }
    }

	for (int c = 0; c < frame.cols; c++) 
	{
        for (int r = 0; r < center_y; r++)
		{
			if((gray_image.at<uchar>(r+1, c) + gray_image.at<uchar>(r+2, c) + gray_image.at<uchar>(r+3, c) + gray_image.at<uchar>(r+4, c) + gray_image.at<uchar>(r+5, c)) - 5*gray_image.at<uchar>(r, c) > 80) // 60
			{
				dst.at<uchar>(r+5, c-20) = 255;
				dst.at<uchar>(r+6, c-20) = 255;
				dst.at<uchar>(r+7, c-20) = 255;
				
				dst.at<uchar>(r+5, c-15) = 255;
				dst.at<uchar>(r+6, c-15) = 255;
				dst.at<uchar>(r+7, c-15) = 255;
				
				dst.at<uchar>(r+5, c-10) = 255;
				dst.at<uchar>(r+6, c-10) = 255;
				dst.at<uchar>(r+7, c-10) = 255;
			}
      }
    }

	for (int c = 0; c < frame.cols; c++) 
	{
        for (int r = center_y; r < frame.rows; r++)
		{
			if(5*gray_image.at<uchar>(r, c) - (gray_image.at<uchar>(r+1, c) + gray_image.at<uchar>(r+2, c) + gray_image.at<uchar>(r+3, c) + gray_image.at<uchar>(r+4, c) + gray_image.at<uchar>(r+5, c)) > 80) // 60
			{
				dst.at<uchar>(r-10, c+10) = 255;
				dst.at<uchar>(r-11, c+10) = 255;
				dst.at<uchar>(r-12, c+10) = 255;

				dst.at<uchar>(r-10, c+15) = 255;
				dst.at<uchar>(r-11, c+15) = 255;
				dst.at<uchar>(r-12, c+15) = 255;
			}
        }
    }

	// imshow("dst", dst);

	circle(gray_image, Point(center_x,center_y), 10, Scalar(255, 255, 255), 2);

	if(camera == 0)
	{
		imshow("left circle mean", gray_image);
	}
	else
	{
		imshow("right circle mean", gray_image);
	}

	dilate(dst, dst, Mat(), Point(-1, -1), 2);
	// erode(edge, edge, Mat(), Point(-1, -1), 1);

	return dst;
}


/**
 * @brief 캘리용 함수
 * 
 * @param frame 입력 영상
 * @param mask 이진화된 영상 (HSV로 이진화하든 어쨌든 이진화된 영상)
 * @return Point 
 */
Point StereoVision::find_ball(Mat& frame, Mat& mask) {

	vector<vector<Point> > contours;

	findContours(mask, contours, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE);

	// Sort the contours to find the biggest one
	sort(contours.begin(), contours.end(), [](const vector<Point>& c1, const vector<Point>& c2) {
		return contourArea(c1, false) < contourArea(c2, false);
	});

	if (contours.size() > 0) {

		vector<Point> largestContour = contours[contours.size() - 1];
		Point2f center;
		float radius;
		minEnclosingCircle(largestContour, center, radius);
		Moments m = moments(largestContour);
		Point centerPoint(m.m10 / m.m00, m.m01 / m.m00);

		// Only preceed if the radius is grater than a minimum threshold
		if (radius > 10) {
			// Draw the circle and centroid on the frame
			circle(frame, center, int(radius), (0, 255, 255), 2);
			circle(frame, centerPoint, 5, (0, 0, 255), -1);
		}

		return centerPoint;
	}
	return { 0,0 };
}

/**
 * @brief 스테레오 카메라 만들 때 사용하는 함수, 초기 제작할 때 수평을 맞추기 위해서 사용함
 * 
 * @param frame 입력 영상
 * @param camera 카메라 번호 0 = 왼쪽, 1 = 오른쪽
 */
void StereoVision::line_symmetry(Mat& frame, int camera)
{
	//left camera, right camera 한 평면 위에 놓는 작업

	Mat img = frame.clone();

	rectangle(img, Rect(Point(635,0),Point(645,720)),Scalar(0,255,0),2,4,0);
	rectangle(img, Rect(Point(0,680),Point(1280,690)),Scalar(0,255,0),2,4,0);
	rectangle(img, Rect(Point(0,640),Point(1280,650)),Scalar(0,255,0),2,4,0);
	rectangle(img, Rect(Point(0,600),Point(1280,610)),Scalar(0,255,0),2,4,0);
	rectangle(img, Rect(Point(0,560),Point(1280,570)),Scalar(0,255,0),2,4,0);
	rectangle(img, Rect(Point(0,520),Point(1280,530)),Scalar(0,255,0),2,4,0);
	rectangle(img, Rect(Point(0,480),Point(1280,490)),Scalar(0,255,0),2,4,0);
	rectangle(img, Rect(Point(0,360),Point(1280,370)),Scalar(0,255,0),2,4,0);

	if(camera == 0)
	{
		imshow("left_line_symmetry", img);
	}
	else
	{
		imshow("right_line_symmetry", img);
	}
}

/**
 * @brief 이진화한 영상에서 중심점을 찾고 하단, 중단, 상단의 x,y좌표를 double 형의 자료형으로 저장함
 * 
 * @param img 입력 영상 (이진화된 영상을 넣으면 됨)
 * @param array double자료형의 배열(바닥 x,y, 가운데 x,y, 상단 x,y 를 저장함)
 * @param camera 카메라 번호 0 = 왼쪽, 1 = 오른쪽
 * @return double* 
 */
double *StereoVision::find_center(Mat &img, double array[], int camera)
{
	Mat mask = img.clone();
    // contours
    vector<vector<Point>> contours;
    vector<Vec4i> hierarchy;
    findContours(mask, contours, hierarchy, RETR_LIST, CHAIN_APPROX_SIMPLE); // CHAIN_APPROX_SIMPLE 덕분에 직선을 제외한 곡선부분을 contour 하지 않음음

    Scalar color(rand() & 255, rand() & 255, rand() & 255);

    int lrgctridx = 0;
    int minarea = 1000000;
    double nowarea = 0;

	vector<Point2f> approx;

	// for (size_t i = 0; i < contours.size(); i++)
	// {
	// 	approxPolyDP(Mat(contours[i]), approx, arcLength(Mat(contours[i]), true)*0.02, true);
	// 	nowarea = contourArea(Mat(approx));
	// 	int vertex = approx.size();

	// 	vector<Point> hull;
    //     convexHull(Mat(contours[lrgctridx]), hull, false);

	// 	if(vertex > 3 && vertex < 7)
	// 	{
	// 		if ((nowarea > 50000) && (nowarea < 300000))		// 일단 25000이었음
	// 		{
	// 			if(nowarea < minarea)
	// 			{
	// 				minarea = nowarea;
	// 				lrgctridx = i;
	// 			}
	// 		}
	// 	}
	// }

	int min_y = 1000;
	Mat drawing11 = Mat::zeros( mask.size(), CV_8UC3 );

	for (size_t i = 0; i < contours.size(); i++)
	{
		approxPolyDP(Mat(contours[i]), approx, arcLength(Mat(contours[i]), true)*0.02, true);
		int vertex = approx.size();
		
		Moments m = moments(contours[i], true);
		Point p(m.m10/m.m00, m.m01/m.m00);
		
		vector<Point> hull;
        convexHull(Mat(contours[i]), hull, false);

		nowarea = contourArea(Mat(hull));

		// cout << nowarea << endl;

		vector<vector<Point>> fake_hull;
        fake_hull.push_back(hull);
        drawContours(drawing11, fake_hull, 0, Scalar(255, 255, 255), 2, LINE_8);

		if(vertex > 3)
		{
			if ((nowarea > 40000) && (nowarea < 300000))		// 일단 25000이었음
			{
				if(p.y < min_y)
				{
					min_y = p.y;
					lrgctridx = i;

					for(i=0; i<hull.size(); i++)
					{
						circle(drawing11, Point(hull[i].x, hull[i].y), 10, Scalar(255, 0, 0), -1);
					}
					cout << " 넓이 : " << nowarea << endl;
				}
			}
		}
	}
	// imshow("all contour hull ", drawing11);
	// cout << "contour size = " << minarea << endl;

    if(contours.size() > 0)
    {
        Mat drawing = Mat::zeros( mask.size(), CV_8UC3 );

        // 모든 외각선 그리기
        // for(int idx = 0; idx >= 0; idx = hierarchy[idx][0])
        // {
        //     drawContours( drawing, contours, idx, color, 2, LINE_8, hierarchy);
        // }

        // 특정한 외각선만 그리기
        drawContours( drawing, contours, lrgctridx, color, 2, LINE_8, hierarchy);

        vector<Point> hull;
        convexHull(Mat(contours[lrgctridx]), hull, false);

        vector<vector<Point>> fake_hull;
        fake_hull.push_back(hull);
        drawContours(drawing, fake_hull, 0, color, 2, LINE_8);

        int top_x_left = hull[0].x;
	    int top_y_left = hull[0].y;
        int top_num_left = 0;

        int bottom_x_left = hull[0].x;
        int bottom_y_left = hull[0].y;
        int bottom_num_left = 0;

        int top_x_right = hull[0].x;
	    int top_y_right = hull[0].y;
        int top_num_right = 0;

        int bottom_x_right = hull[0].x;
        int bottom_y_right = hull[0].y;
        int bottom_num_right = 0;

        for(int i = 0; i < hull.size(); i++)
        {
            // if(hull[i].y < top_y_left)
            // {
            //     top_x_left = hull[i].x;
            //     top_y_left = hull[i].y;
            //     top_num_left = i;
            // }
            if(sqrt(pow(hull[i].x - img.cols*7/8, 2) + pow(hull[i].y - 0, 2)) < sqrt(pow(top_x_right - img.cols*7/8, 2) + pow(top_y_right - 0, 2)))
            {
                top_x_right = hull[i].x;
                top_y_right = hull[i].y;
                top_num_right = i;
            }
            if((1*sqrt(pow(hull[i].x - 0, 2) + pow(hull[i].y - img.rows, 2)) + 9*hull[i].x) < (1*sqrt(pow(bottom_x_left - 0, 2) + pow(bottom_y_left - img.rows, 2)) + 9*bottom_x_left))
            {
                bottom_x_left = hull[i].x;
                bottom_y_left = hull[i].y;
                bottom_num_left = i;
            }
            if(sqrt(pow(hull[i].x - img.cols, 2) + pow(hull[i].y - img.rows, 2)) < sqrt(pow(bottom_x_right - img.cols, 2) + pow(bottom_y_right - img.rows, 2)))
            {
                bottom_x_right = hull[i].x;
                bottom_y_right = hull[i].y;
                bottom_num_right = i;
            }
        }

		double daegaksun = sqrt(pow(bottom_x_left - top_x_right, 2) + pow(bottom_y_left - top_y_right, 2));
		double long_sin = 0;
		double fake_sin;

		for(int j=0; j < hull.size(); j++)
		{
			if((hull[j].y < bottom_y_left -50) && (hull[j].x < top_x_right - 50) && (hull[j].x < bottom_x_right - 50))
			{
				double sasun1 = sqrt(pow(hull[j].x - bottom_x_left, 2) + pow(hull[j].y - bottom_y_left, 2));
				double sasun2 = sqrt(pow(hull[j].x - top_x_right, 2) + pow(hull[j].y - top_y_right, 2));

				double theta = acos((pow(sasun1, 2) - pow(sasun2, 2) + pow(daegaksun, 2)) / (2*sasun1*daegaksun));

				fake_sin = sasun1 * sin(theta);

				if(fake_sin > long_sin)
				{
					long_sin = fake_sin;

					top_x_left = hull[j].x;
					top_y_left = hull[j].y;
				}

			}
		}

        double mean_top_x = (double)((top_x_left + top_x_right) / 2.0);
        double mean_top_y = (double)((top_y_left + top_y_right) / 2.0);
		double mean_mid_x = (double)((top_x_left+top_x_right+bottom_x_left+bottom_x_right)/4.0);
		double mean_mid_y = (double)((top_y_left+top_y_right+bottom_y_left+bottom_y_right)/4.0);
        double mean_bottom_x = (double)((bottom_x_left + bottom_x_right) / 2.0);
        double mean_bottom_y = (double)((bottom_y_left + bottom_y_right) / 2.0);

        circle(drawing, Point((int)mean_top_x, (int)mean_top_y), 10, Scalar(0, 0, 255), -1);
		circle(drawing, Point((int)mean_mid_x, (int)mean_mid_y), 10, Scalar(0, 255, 0), -1);
        circle(drawing, Point((int)mean_bottom_x, (int)mean_bottom_y), 10, Scalar(255, 0, 0), -1);
        
        circle(drawing, Point(top_x_left, top_y_left), 4, Scalar(255, 255, 255), -1);
        circle(drawing, Point(top_x_right, top_y_right), 4, Scalar(255, 255, 255), -1);
        circle(drawing, Point(bottom_x_left, bottom_y_left), 4, Scalar(255, 255, 255), -1);
        circle(drawing, Point(bottom_x_right, bottom_y_right), 4, Scalar(255, 255, 255), -1);

        array[0] = mean_bottom_x;
		array[1] = mean_bottom_y;
		array[2] = mean_mid_x;
		array[3] = mean_mid_y;
		array[4] = mean_top_x;
		array[5] = mean_top_y;

		if(camera == 0)
		{
			imshow("Left", drawing);
		}
		else
		{
			imshow("Right", drawing);
		}
		
		return array;
    }
    else
    {
        return array;
    }
}

/**
 * @brief 실제 erp의 GPS를 기준으로 X, Z값을 계산하는 함수
 * 
 * left_point와 right_point는 서로 대응되는 점을 넣어야 함
 * ex) {left_array[0],left_array[1]}를 넣으면 {right_array[0],right_array[1]}를 넣어야 함
 * 
 * @param left_point find_center 함수로 구한 좌측 카메라에서의 x,y값
 * @param right_point find_center 함수로 구한 우측 카메라에서의 x,y값
 * @param leftFrame 왼쪽화면 입력영상
 * @param rightFrame 오른쪽화면 입력영상
 * @param alpha 카메라가 고개를 숙인 각도 (처음 find_ball함수를 이용해 캘리를 하면서 구함)
 * @param beta 카메라가 틀어진 각도 (처음 find_ball함수를 이용해 캘리를 하면서 구함)
 * @return Point2d (실제 X거리값, 실제 Z거리값, cm단위임)
 */
Point2d StereoVision::find_XZ(Point2d left_point, Point2d right_point, Mat& leftFrame, Mat& rightFrame, float alpha, float beta)
{	
	float x_0 = 0;
	float y_0 = 0;
	if ((rightFrame.cols == leftFrame.cols) && (rightFrame.rows == leftFrame.rows))
	{	
		x_0 = rightFrame.cols/2;
		y_0 = rightFrame.rows/2;
	}
	else {
		cout << "Left and Right Camera frames do not have the same pixel width" << endl;	
	}

	float xLeft = left_point.x;
	float xRight = right_point.x;
	float yLeft = left_point.y;
	float yRight = right_point.y;

	float realX = 0;
	float realY = 0;
	float realZ = 0;
	float distance = 0;

	if(xLeft != x_0)
	{
		realX = (float)baseline/(1 - (x_0 - xRight)/(x_0 - xLeft));
		realZ = abs(realX*focal_pixels/(x_0 - xLeft));
	}
	else if(xRight != x_0)
	{
		realX = -(float)baseline/(1 - (x_0 - xLeft)/(x_0 - xRight));
		realZ = abs(realX*focal_pixels/(x_0 - xRight));
		realX = realX + (float)baseline; //왼쪽 카메라 기준
	}
	else
	{
		realX = 0;
		realY = 0;
	}
	realY = realZ*(2*y_0-yLeft-yRight)/(2*focal_pixels);

	distance = sqrt(pow(realX,2)+pow(realY,2) + pow(realZ,2));

	// cout << " realX : " << realX << "   realY : "<< realY << "     realZ : " << realZ << endl << endl;
	// cout << " distance : " << distance << endl;
	
	// cout << " 영점 조절 : " << realX << endl;
	
	//ERP 기준 좌표로 변환
	alpha = alpha * CV_PI / 180;
	beta = beta * CV_PI / 180;

	float fakeZ = realZ;
	float fakeY = realY;

	float theta = atan(fakeY/fakeZ) - alpha;
	realZ = sqrt(pow(fakeZ,2)+pow(fakeY,2))*cos(theta);
	realY = sqrt(pow(fakeZ,2)+pow(fakeY,2))*sin(theta);

	float realZ_copy = realZ;
	float realX_copy = realX;

	float gama = atan(realX/realZ) + beta;
	realZ = sqrt(pow(realZ_copy,2)+pow(realX_copy,2))*cos(gama);
	realX = sqrt(pow(realZ_copy,2)+pow(realX_copy,2))*sin(gama);
	
	// float angle = 0;
	// angle = atan(realX/realZ)*180/CV_PI;

	// cout << "realZ : " << realZ << "  realX : " << realX << endl <<endl;
	return {realZ, realX};
}

/**
 * @brief 그림자 문제를 해결하기 위해 적응형 이진화 함수를 사용해 색공간이 아닌 다른 방법으로 영상을 이진화함
 * 
 * @param src 입력영상 
 * @return Mat 이진화된 영상 
 */
Mat StereoVision::adaptiveThreshold_parking(Mat src)
{
	Mat image;
	Mat binary;

	image = src.clone();

	resize(image, image, Size(640, 480));

	imshow("cap", image);

	cvtColor(image, binary, CV_BGR2GRAY);
	// namedWindow("dst");
	// createTrackbar("Block_Size", "dst", 0, 200, on_trackbar, (void*)&binary);
	// setTrackbarPos("Block_Size", "dst", 11);

	adaptiveThreshold(binary, binary, 255, ADAPTIVE_THRESH_GAUSSIAN_C, THRESH_BINARY, 9, 5);

	Mat binary_inv;

	binary_inv = ~binary;

	// morphologyEx(binary, binary, MORPH_OPEN, Mat(), Point(-1, -1), 3);

	morphologyEx(binary_inv, binary_inv, MORPH_CLOSE, Mat(), Point(-1, -1), 1);

	erode(binary_inv, binary_inv, Mat());

	resize(binary_inv, binary_inv, Size(640, 480));

	imshow("dst", binary_inv);

	return binary_inv;
}

/**
 * @brief 평행주차용으로 개발했으나 라바콘이 예상과는 다르게 사용되어 쓸 일이 없음
 * 
 * @param img 
 * @param camera 
 * @return Point
 */
Point StereoVision::back_park(Mat &img, int camera)
{
	Mat mask = img.clone();

	vector<vector<Point>> contours;
	vector<Vec4i> hierarchy;

	dilate(mask, mask, Mat::ones(Size(3, 3), CV_8UC1), Point(-1, -1), 2);

	findContours(mask, contours, hierarchy,RETR_LIST, CHAIN_APPROX_SIMPLE);

	Scalar color(rand() & 255, rand() & 255, rand() & 255);

    int lrgctridx = 0;
    int minarea = 1000000;
	int maxarea = 0;
    double nowarea = 0;
	bool find_contour = false;
	Point contour_moment = {0,0};
	int minDistance = 10000;

	for (size_t i = 0; i < contours.size(); i++)
	{
		nowarea = contourArea(contours[i]);
		Moments m = moments(contours[i], true);
		Point p(m.m10/m.m00, m.m01/m.m00);

		float d = sqrt(pow(p.x-img.cols*5/6,2)+pow(p.y-img.rows*5/6,2));

		// if ((nowarea > 4000) && (nowarea < 30000) && d > 300)
		// {
		// 	if(nowarea > maxarea)
		// 	{
		// 		maxarea = nowarea;
		// 		lrgctridx = i;
		// 		contour_moment = p;
		// 		find_contour = true;
		// 		// cout << " size : " << nowarea << endl;
		// 	}
		// }
		// cout << "!!! : " << sqrt(pow(img.cols/6,2)+pow(img.rows/6,2)) << endl;
		if ((nowarea > 2000) && (nowarea < 30000) && (d > 250))
		{
			if(d < minDistance)
			{
				minDistance = d;
				lrgctridx = i;
				contour_moment = p;
				find_contour = true;
				// cout << " size : " << nowarea << endl;
				// cout << " d : " << d << endl;
			}
		}
	}

	int bottom_x = 0;
	int bottom_y = 0;

	if(find_contour == true)
	{
		Mat drawing = Mat::zeros( mask.size(), CV_8UC3 );

		// drawContours( mask, contours, lrgctridx, Scalar(255, 255, 255), 2, LINE_8, hierarchy);

        vector<Point> hull;
        convexHull(Mat(contours[lrgctridx]), hull, false);

        vector<vector<Point>> fake_hull;
        fake_hull.push_back(hull);
        drawContours(drawing, fake_hull, 0, color, 4, LINE_8);

		bottom_x = hull[0].x;
        bottom_y = hull[0].y;

		for(int i = 0; i < hull.size(); i++)
        {
            if(hull[i].y > bottom_y)
            {
                bottom_x = hull[i].x;
                bottom_y = hull[i].y;
            }
        }

		circle(drawing, {bottom_x,bottom_y}, 8, Scalar(0, 255, 0), -1);

        circle(drawing, contour_moment, 8, Scalar(0, 0, 255), -1);

		if(camera == 0)
		{
			imshow("Left", drawing);
		}
		else
		{
			imshow("Right", drawing);
		}
		
		return {bottom_x,bottom_y}; // contour_moment
    }
    else
    {
        return {bottom_x,bottom_y}; //contour_moment
    }
}

Scalar StereoVision::IMG_mean(Mat img, int X, int width, int Y, int height, int camera)
{
	Mat img_roi = img(Rect(Point(X, Y), Point(X + width, Y + height)));
	Scalar average = mean(img_roi);

	if(camera == 0)
	{
		// imshow("left_roi",img_roi);
	}
	else
	{
		// imshow("right_roi",img_roi);
	}

	// std::cout << average << std::endl;
	return average;
}
